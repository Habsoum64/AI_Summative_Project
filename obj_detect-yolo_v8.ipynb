{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec41b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.223 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-10750H 2.60GHz)\n",
      "Setup complete âœ… (12 CPUs, 15.8 GB RAM, 663.2/933.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# %pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38021dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d9a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'C:/Users/Mohamed Habib/Documents/AI Summative Project/Model Development/coco_90.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect train model=yolov8s.yaml data=coco_90.yml epochs=10 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4fa534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8s.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04daf5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.226 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.223 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-10750H 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=coco_90.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train15\n",
      "Overriding model.yaml nc=80 with nc=90\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2150878  ultralytics.nn.modules.head.Detect           [90, [128, 256, 512]]         \n",
      "YOLOv8s summary: 225 layers, 11170430 parameters, 11170414 gradients, 28.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train15', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mohamed Habib\\Documents\\AI Summative Project\\labels\\train.cache... 3200 images, 27 backgrounds\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mohamed Habib\\Documents\\AI Summative Project\\labels\\val.cache... 800 images, 12 backgrounds, 0 c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train15\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000106, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train15\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G        3.5      5.865      4.265        117        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [51:08<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040   0.000493    0.00153   0.000545   0.000148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      3.509      5.444      4.019         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [47:09<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00141     0.0145     0.0013   0.000321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      3.414      5.229      3.799        146        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [44:34<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:32"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040   0.000609      0.024   0.000667   0.000209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      3.275      5.071       3.63        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [44:02<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00151     0.0365    0.00157   0.000458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      3.159       4.95      3.491         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [43:49<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040      0.382    0.00466    0.00189    0.00066\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      3.017      4.822      3.345         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [44:21<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:33"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00299     0.0431    0.00443     0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      2.925      4.729      3.248        170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [44:05<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00252     0.0478    0.00386    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      2.825      4.669      3.162        129        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [43:52<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040      0.399     0.0171    0.00489    0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      2.784      4.606      3.104        115        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [43:43<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00375     0.0601    0.00678    0.00223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      2.727      4.537      3.057         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [44:05<00:00, 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [03:31"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00366     0.0737    0.00608    0.00232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 8.114 hours.\n",
      "Optimizer stripped from runs\\detect\\train15\\weights\\last.pt, 22.6MB\n",
      "Optimizer stripped from runs\\detect\\train15\\weights\\best.pt, 22.6MB\n",
      "\n",
      "Validating runs\\detect\\train15\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.223 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-10750H 2.60GHz)\n",
      "YOLOv8s summary (fused): 168 layers, 11160414 parameters, 0 gradients, 28.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [02:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       6040    0.00367     0.0737     0.0061    0.00232\n",
      "                person        800       1793    0.00719      0.541      0.068     0.0207\n",
      "               bicycle        800         46          0          0          0          0\n",
      "                   car        800        347    0.00508      0.144    0.00435    0.00126\n",
      "            motorcycle        800         94    0.00915      0.138    0.00853    0.00355\n",
      "              airplane        800         25    0.00473       0.16     0.0037    0.00131\n",
      "                   bus        800         50    0.00481       0.24    0.00602    0.00218\n",
      "                 train        800         33    0.00447      0.424    0.00775    0.00266\n",
      "                 truck        800         72    0.00376     0.0972     0.0034    0.00112\n",
      "                  boat        800         63          0          0          0          0\n",
      "         traffic light        800        143          0          0          0          0\n",
      "          fire hydrant        800         15          0          0          0          0\n",
      "             stop sign        800         13          0          0          0          0\n",
      "         parking meter        800         11          0          0          0          0\n",
      "                 bench        800         50    0.00602       0.08     0.0073    0.00244\n",
      "                  bird        800         84     0.0116     0.0119    0.00623   0.000623\n",
      "                   cat        800         36    0.00582      0.472     0.0365     0.0147\n",
      "                   dog        800         34      0.004      0.265    0.00625     0.0028\n",
      "                 horse        800         46    0.00761       0.13    0.00684    0.00295\n",
      "                 sheep        800         49          0          0          0          0\n",
      "                   cow        800         55    0.00415     0.0364    0.00236     0.0013\n",
      "              elephant        800         27    0.00246      0.111    0.00291    0.00104\n",
      "                  bear        800         12    0.00917     0.0833    0.00589    0.00274\n",
      "                 zebra        800         56     0.0145      0.304     0.0281      0.011\n",
      "               giraffe        800         63     0.0173     0.0794    0.00968    0.00515\n",
      "              backpack        800         52          0          0          0          0\n",
      "              umbrella        800         19          0          0          0          0\n",
      "               handbag        800         77          0          0          0          0\n",
      "                   tie        800         45          0          0          0          0\n",
      "              suitcase        800         22          0          0          0          0\n",
      "               frisbee        800         32          0          0          0          0\n",
      "                  skis        800         32          0          0          0          0\n",
      "             snowboard        800         10          0          0          0          0\n",
      "           sports ball        800         47          0          0          0          0\n",
      "                  kite        800         51     0.0178     0.0588     0.0113     0.0071\n",
      "          baseball bat        800         26          0          0          0          0\n",
      "        baseball glove        800         28          0          0          0          0\n",
      "            skateboard        800         28          0          0          0          0\n",
      "             surfboard        800         32          0          0          0          0\n",
      "         tennis racket        800         20          0          0          0          0\n",
      "                bottle        800        164          0          0          0          0\n",
      "            wine glass        800         63          0          0          0          0\n",
      "                   cup        800        112          0          0          0          0\n",
      "                  fork        800         24          0          0          0          0\n",
      "                 knife        800         46          0          0          0          0\n",
      "                 spoon        800         27          0          0          0          0\n",
      "                  bowl        800        108     0.0087       0.12    0.00842    0.00467\n",
      "                banana        800         82          0          0          0          0\n",
      "                 apple        800         25          0          0          0          0\n",
      "              sandwich        800         20     0.0208        0.3     0.0294    0.00753\n",
      "                orange        800         39     0.0063     0.0769     0.0113    0.00216\n",
      "              broccoli        800         60          0          0          0          0\n",
      "                carrot        800         48    0.00313     0.0833      0.003    0.00136\n",
      "               hot dog        800         25     0.0225       0.16     0.0215    0.00901\n",
      "                 pizza        800         49    0.00664      0.204     0.0569     0.0273\n",
      "                 donut        800         72    0.00909     0.0139    0.00478   0.000478\n",
      "                  cake        800         33    0.00571     0.0303    0.00297   0.000297\n",
      "                 chair        800        319    0.00265      0.069    0.00157   0.000428\n",
      "                 couch        800         55    0.00788      0.218     0.0133     0.0049\n",
      "          potted plant        800         70          0          0          0          0\n",
      "                   bed        800         20    0.00359        0.5     0.0186    0.00478\n",
      "          dining table        800        120     0.0101      0.342     0.0556     0.0265\n",
      "                toilet        800         31          0          0          0          0\n",
      "                    tv        800         35     0.0339     0.0571     0.0182    0.00548\n",
      "                laptop        800         38    0.00554     0.0526    0.00332   0.000835\n",
      "                 mouse        800         12          0          0          0          0\n",
      "                remote        800         64          0          0          0          0\n",
      "              keyboard        800         16          0          0          0          0\n",
      "            cell phone        800         40          0          0          0          0\n",
      "             microwave        800         12          0          0          0          0\n",
      "                  oven        800         21          0          0          0          0\n",
      "               toaster        800          1          0          0          0          0\n",
      "                  sink        800         39          0          0          0          0\n",
      "          refrigerator        800         23          0          0          0          0\n",
      "                  book        800        269          0          0          0          0\n",
      "                 clock        800         40          0          0          0          0\n",
      "                  vase        800         41          0          0          0          0\n",
      "              scissors        800          5          0          0          0          0\n",
      "            teddy bear        800         28    0.00407      0.214    0.00766    0.00299\n",
      "            toothbrush        800          6          0          0          0          0\n",
      "Speed: 2.3ms preprocess, 195.0ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train = model.train(data='coco_90.yml', epochs=10, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c933f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.020969,           0,   0.0013448,   0.0034245,   0.0013006,   0.0021612,   0.0026612,  0.00097232,           0,           0,           0,   0.0022804,           0,           0,   0.0024629,  0.00060335,    0.014853,   0.0028669,   0.0026897,           0,  0.00084424,   0.0010542,   0.0027457,    0.010529,\n",
       "          0.005275,   0.0022804,           0,           0,   0.0022804,   0.0022804,           0,           0,           0,           0,           0,           0,           0,   0.0071972,           0,           0,           0,           0,           0,           0,   0.0022804,           0,           0,           0,\n",
       "                 0,           0,   0.0047043,           0,           0,    0.007539,   0.0021448,           0,    0.001083,   0.0089225,    0.026277,  0.00046864,  0.00029149,  0.00039868,    0.004998,           0,   0.0048174,   0.0022804,    0.024913,   0.0022804,   0.0022804,           0,   0.0022804,   0.0057519,\n",
       "        0.00084142,           0,           0,           0,           0,           0,           0,           0,           0,           0,   0.0022804,           0,           0,           0,           0,   0.0030449,   0.0022804,           0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model\n",
    "#metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "#metrics.box.map50  # map50\n",
    "#metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953095bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
